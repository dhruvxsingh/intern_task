# ğŸ›ï¸ Croma Product Scraper â€“ Full Stack Internship Task

## ğŸ“š Overview  
This is a full-stack web application, designed to **scrape live product data** from [Croma's Televisions & Accessories page](https://www.croma.com/televisions-accessories/c/997) and display the data in a **stylish frontend interface**. The project uses **Python, Flask, Redis, Vue.js**, and beautiful custom styling to build an end-to-end pipeline from data scraping to display.

---

## ğŸš€ Features

- ğŸ“¦ Scrapes product **title, price, discount**, and **extra offers** from Croma  
- ğŸ“¥ Stores scraped data in **Redis** for fast retrieval  
- ğŸ”Œ Backend API built with **Flask**, exposes `/scraped-content`  
- ğŸ’… Frontend built with **Vue.js**, styled to match dark UI specs  
- ğŸ¯ Modular, clean and readable code in both frontend and backend

---

## ğŸ§© Tech Stack

|
 Layer      
|
 Technology                  
|
|
------------
|
-----------------------------
|
|
 Data       
|
 Web Scraping with 
`BeautifulSoup`
|
|
 Storage    
|
 Redis (via Docker)          
|
|
 Backend    
|
 Python 3.8+, Flask          
|
|
 Frontend   
|
 Vue.js (CLI-based), CSS     
|
|
 Dev Tools  
|
 Docker, venv, npm, Git      
|

---

## ğŸ’¡ Architecture

```text
+-----------------------+
|   Croma Website       |
|  (source of data)     |
+-----------+-----------+
            |
Scrape via requests + bs4
            |
            v
+-----------------------+
|     Backend (Flask)   |
|  â†” Redis (cached data)|
+-----------+-----------+
            |
Serve as JSON (API: /scraped-content)
            v
+-----------------------+
|   Frontend (Vue.js)   |
|   Fetch & Render Cards|
+-----------------------+

âš™ï¸ How to Run It Locally
ğŸ“Œ Requires: Python 3.8+, Docker, and Node.js 14+

ğŸ”§ Backend Setup
# Clone the repo
git clone git@github.com:dhruvxsingh/intern_task.git
cd intern_task

# Create virtual environment
python -m venv venv
source venv/bin/activate       # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Start Redis using Docker
docker run --name redis -p 6379:6379 -d redis     # only once
docker start redis                                 # from next time

# Run scraper to fill Redis
python backend/scraper.py

# Start Flask server
python backend/app.py

ğŸ“Œ Your API will be running at:
http://127.0.0.1:5000/scraped-content

ğŸŒ Frontend Setup
cd frontend
npm install
npm run serve

ğŸ“Œ App will be available at:
http://localhost:8080

ğŸ› ï¸ Folder Structure
croma-scraper/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py            # Flask API
â”‚   â”œâ”€â”€ scraper.py        # Web scraping logic
â”‚   â””â”€â”€ requirements.txt  # Python dependencies
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/App.vue       # Vue front-end
â”‚   â”œâ”€â”€ package.json      # Frontend configuration
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ README.md             # This file!
â””â”€â”€ venv/                 # Python virtual environment
